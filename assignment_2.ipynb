{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO5uZaZtpEv-"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvNSP61sp7kQ"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRrr_lEZu12u"
      },
      "source": [
        "# As a sanity check, we print out the size of the training and test data.\n",
        "print('Training data shape: ', X_train.shape)\n",
        "print('Training labels shape: ', y_train.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS0RRk7xu-zD"
      },
      "source": [
        "# Visualize some examples from the dataset.\n",
        "# We show a few examples of training images from each class.\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(classes)\n",
        "samples_per_class = 7\n",
        "for y, cls in enumerate(classes):\n",
        "    idxs = np.flatnonzero(y_train == y)\n",
        "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
        "    for i, idx in enumerate(idxs):\n",
        "        plt_idx = i * num_classes + y + 1\n",
        "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
        "        plt.imshow(X_train[idx].astype('uint8'))\n",
        "        plt.axis('off')\n",
        "        if i == 0:\n",
        "            plt.title(cls)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHVRGUVwvBT1"
      },
      "source": [
        "# Subsample the data for more efficient code execution in this exercise\n",
        "num_training = 5000\n",
        "mask = list(range(num_training))\n",
        "X_train = X_train[mask]\n",
        "y_train = y_train[mask]\n",
        "\n",
        "num_test = 500\n",
        "mask = list(range(num_test))\n",
        "X_test = X_test[mask]\n",
        "y_test = y_test[mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4i8-w8pvD-n"
      },
      "source": [
        "# Reshape the image data into rows\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "binRmAuuvG15"
      },
      "source": [
        "class KNearestNeighbor(object):\n",
        "  \"\"\" a kNN classifier with L2 distance \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train(self, X, y):\n",
        "   \n",
        "    self.X_train = X\n",
        "    self.y_train = y\n",
        "\n",
        "  def predict(self, X, k=1, num_loops=0):\n",
        "   \n",
        "    if num_loops == 0:\n",
        "      dists = self.compute_distances_no_loops(X)\n",
        "    elif num_loops == 1:\n",
        "      dists = self.compute_distances_one_loop(X)\n",
        "    elif num_loops == 2:\n",
        "      dists = self.compute_distances_two_loops(X)\n",
        "    else:\n",
        "      raise ValueError('Invalid value %d for num_loops' % num_loops)\n",
        "\n",
        "    return self.predict_labels(dists, k=k)\n",
        "\n",
        "  def compute_distances_two_loops(self, X):\n",
        "    \n",
        "    num_test = X.shape[0]\n",
        "    num_train = self.X_train.shape[0]\n",
        "    dists = np.zeros((num_test, num_train))\n",
        "    for i in range(num_test):\n",
        "      for j in range(num_train):\n",
        "        dists[i, j] = np.linalg.norm(X[i]-self.X_train[j])\n",
        "\n",
        "    return dists\n",
        "\n",
        "  def compute_distances_one_loop(self, X):\n",
        "    \n",
        "    num_test = X.shape[0]\n",
        "    num_train = self.X_train.shape[0]\n",
        "    dists = np.zeros((num_test, num_train))\n",
        "    for i in range(num_test):\n",
        "      # Note axis=1 computes norm along rows\n",
        "      dists[i] = np.linalg.norm(X[i]-self.X_train, axis=1)\n",
        "\n",
        "    return dists\n",
        "\n",
        "  def compute_distances_no_loops (self, X):\n",
        "   \n",
        "    num_test = X.shape[0]\n",
        "    num_train = self.X_train.shape[0]\n",
        "\n",
        "    x2 = np.sum(X**2, axis=1).reshape((num_test, 1))\n",
        "    y2 = np.sum(self.X_train**2, axis=1).reshape((1, num_train))\n",
        "    xy = -2*np.matmul(X, self.X_train.T)\n",
        "    dists = np.sqrt(x2 + xy + y2)\n",
        "\n",
        "    return dists\n",
        "\n",
        "  def predict_labels(self, dists, k=1):\n",
        "    \n",
        "    num_test = dists.shape[0]\n",
        "    y_pred = np.zeros(num_test, dtype=int)\n",
        "    for i in range(num_test):\n",
        "      closest_x = np.argsort(dists[i])[:k]\n",
        "      closest_y = [self.y_train[val] for val in closest_x]\n",
        "      labels, counts = np.unique(closest_y, return_counts=True)\n",
        "      y_pred[i] = labels[np.argmax(counts)]\n",
        "\n",
        "    return y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB9YEsmHyf8X"
      },
      "source": [
        "classifier = KNearestNeighbor()\n",
        "classifier.train(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui-zRyyOyqOA"
      },
      "source": [
        "dists = classifier.compute_distances_two_loops(X_test)\n",
        "print(dists.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTRfzyCpyxdm"
      },
      "source": [
        "plt.imshow(dists, interpolation='none')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt-KyDLfy5mr"
      },
      "source": [
        "# Now implement the function predict_labels and run the code below:\n",
        "# We use k = 1 (which is Nearest Neighbor).\n",
        "y_test_pred = classifier.predict_labels(dists, k=1)\n",
        "\n",
        "# Compute and print the fraction of correctly predicted examples\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQXM8XKy-C5"
      },
      "source": [
        "y_test_pred = classifier.predict_labels(dists, k=5)\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBhWcqnQzBeH"
      },
      "source": [
        "dists_one = classifier.compute_distances_one_loop(X_test)\n",
        "\n",
        "\n",
        "difference = np.linalg.norm(dists - dists_one, ord='fro')\n",
        "print('Difference was: %f' % (difference, ))\n",
        "if difference < 0.001:\n",
        "    print('Good! The distance matrices are the same')\n",
        "else:\n",
        "    print('Uh-oh! The distance matrices are different')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvHmkNZ9zG0I"
      },
      "source": [
        "\n",
        "dists_two = classifier.compute_distances_no_loops(X_test)\n",
        "\n",
        "# check that the distance matrix agrees with the one we computed before:\n",
        "difference = np.linalg.norm(dists - dists_two, ord='fro')\n",
        "print('Difference was: %f' % (difference, ))\n",
        "if difference < 0.001:\n",
        "    print('Good! The distance matrices are the same')\n",
        "else:\n",
        "    print('Uh-oh! The distance matrices are different')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwYddqJOzXUD"
      },
      "source": [
        "# Let's compare how fast the implementations are\n",
        "def time_function(f, *args):\n",
        "    \"\"\"\n",
        "    Call a function f with args and return the time (in seconds) that it took to execute.\n",
        "    \"\"\"\n",
        "    import time\n",
        "    tic = time.time()\n",
        "    f(*args)\n",
        "    toc = time.time()\n",
        "    return toc - tic\n",
        "\n",
        "two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)\n",
        "print('Two loop version took %f seconds' % two_loop_time)\n",
        "\n",
        "one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)\n",
        "print('One loop version took %f seconds' % one_loop_time)\n",
        "\n",
        "no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)\n",
        "print('No loop version took %f seconds' % no_loop_time)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnl7FEvLziQ8"
      },
      "source": [
        "### Cross-validation\n",
        "\n",
        "We have implemented the k-Nearest Neighbor classifier but we set the value k = 5 arbitrarily. We will now determine the best value of this hyperparameter with cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH0jHcC7zZwd"
      },
      "source": [
        "num_folds = 5\n",
        "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
        "\n",
        "# Check that training set can be equally divided into num_folds portions\n",
        "if num_training/num_folds % num_folds != 0.0:\n",
        "    raise ValueError('Number of training examples not evenly divisible by number of folds.')\n",
        "\n",
        "# Split training set into num_folds lists\n",
        "X_train_folds = np.split(X_train, num_folds)\n",
        "y_train_folds = np.split(y_train, num_folds)\n",
        "\n",
        "\n",
        "k_to_accuracies = {}\n",
        "\n",
        "\n",
        "for k in k_choices:\n",
        "    k_to_accuracies[k] = []\n",
        "    \n",
        "for idx in range(num_folds):\n",
        "    # Use bin with index idx as validation set, rest as training set \n",
        "    X_train_set = np.concatenate((*X_train_folds[:idx], *X_train_folds[idx+1:]), axis=0)\n",
        "    y_train_set = np.concatenate((*y_train_folds[:idx], *y_train_folds[idx+1:]), axis=0)\n",
        "    X_validation_set = X_train_folds[idx]\n",
        "    y_validation_set = y_train_folds[idx]   \n",
        "    num_validation_set = X_validation_set.shape[0]\n",
        "    # Train kNN classifier\n",
        "    classifier = KNearestNeighbor()\n",
        "    classifier.train(X_train_set, y_train_set)\n",
        "    # Compute distances\n",
        "    dists_validate = classifier.compute_distances_no_loops(X_validation_set)\n",
        "    for k in k_choices:\n",
        "        # Predict labels for validation set\n",
        "        y_validation_pred = classifier.predict_labels(dists_validate, k=k)\n",
        "        # Check accuracy\n",
        "        accuracy = (float(np.sum(np.equal(y_validation_pred, y_validation_set)))/num_validation_set)\n",
        "        k_to_accuracies[k].append(accuracy)\n",
        "\n",
        "# Print out the computed accuracies\n",
        "for k in sorted(k_to_accuracies):\n",
        "    for accuracy in k_to_accuracies[k]:\n",
        "        print('k = %d, accuracy = %f' % (k, accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYJSRYL23t3U"
      },
      "source": [
        "for k in k_choices:\n",
        "    accuracies = k_to_accuracies[k]\n",
        "    plt.scatter([k] * len(accuracies), accuracies)\n",
        "\n",
        "# plot the trend line with error bars that correspond to standard deviation\n",
        "\n",
        "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
        "plt.title('Cross-validation on k')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Cross-validation accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtQ0BRxPzokQ"
      },
      "source": [
        "# plot the raw observations\n",
        "for k in k_choices:\n",
        "    accuracies = k_to_accuracies[k]\n",
        "    print('k = %d, average accuracy = %f' % (k, np.average(accuracies)))\n",
        "    plt.scatter([k] * len(accuracies), accuracies)\n",
        "\n",
        "# plot the trend line with error bars that correspond to standard deviation\n",
        "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
        "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
        "plt.title('Cross-validation on k')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Cross-validation accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJOE8B8nzpJ6"
      },
      "source": [
        "best_k = 10\n",
        "\n",
        "classifier = KNearestNeighbor()\n",
        "classifier.train(X_train, y_train)\n",
        "y_test_pred = classifier.predict(X_test, k=best_k)\n",
        "\n",
        "# Compute and display the accuracy\n",
        "num_correct = np.sum(y_test_pred == y_test)\n",
        "accuracy = float(num_correct) / num_test\n",
        "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQHOtczBzsxK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}